{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaptive Echo Cancellation\n",
    "\n",
    "<div align=\"right\"><a href=\"https://people.epfl.ch/paolo.prandoni\">Paolo Prandoni</a>, <a href=\"https://www.epfl.ch/labs/lcav/\">LCAV, EPFL</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will use the adaptive LMS filter to estimate the impulse response of a reverberating room. \n",
    "\n",
    "A typical use case is handsfree telephony: since the received signal, amplified and played by the speaker, is picked up by the microphone, we need to eliminate it from the signal that is transmitted back in order to avoid a feedback loop. The signal picked up by the microphone, however, has been \"processed\" by the speaker and by the room and therefore simple signal subtraction is not sufficient. We need to first estimate the reverberation introduced by the room and pre-filter the received signal with the resulting impulse response before subtracting it from the transmitted signal. \n",
    "\n",
    "The same setup can be used to combat the effects of a a communication channel that introduces multiples echos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.signal as sp\n",
    "import IPython\n",
    "from scipy.io import wavfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (14,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. The echo model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin by implementing an echo filter that simulates the reverbereation in a room. We will use a recursive model in which each reflection introduces a 180-degree phase shift (i.e. a change in sign) together with attenuation and lowpass filtering.\n",
    "\n",
    "<img width=\"750\" style=\"margin: 10px 20px 0 0;\" src=\"echo.jpg\">\n",
    "\n",
    "In the above block diagram, $M$ is the echo's delay, $-1 < \\alpha < 0$ is the attenuation factor for each repetition and $H(z) = (1-\\lambda)/(1 - \\lambda z^{-1})$ is a simple leaky integrator with $\\lambda$ relatively small in order to just attenuate more and more the signal with each reflection.\n",
    "\n",
    "The CCDE governing the system turns out to be \n",
    "\n",
    "$$\n",
    "    y[n] = x[n] − \\lambda x[n − 1] + \\lambda y[n − 1] + \\alpha (1 − \\lambda)y[n − M]\n",
    "$$\n",
    "\n",
    "which is easily implemented as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_echo(x, M, lmb=0.6, alpha=-0.8):\n",
    "    # if the first argument is a scalar, assume the input is a delta sequence of length x\n",
    "    #  in this case, the function returns the truncated impulse response of the room.\n",
    "    if np.isscalar(x):\n",
    "        x = np.zeros(int(x))\n",
    "        x[0] = 1\n",
    "    y = np.zeros(len(x))\n",
    "    for n in range(0, len(x)):\n",
    "        if n >= M:\n",
    "            y[n] = x[n] - lmb * x[n-1] + lmb * y[n-1] + alpha * (1 - lmb) * y[n - M]\n",
    "        elif n > 0:\n",
    "            y[n] = x[n] - lmb * x[n-1] + lmb * y[n-1]\n",
    "        else:\n",
    "            y[n] = x[n]\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting echo system is an IIR filter. Let's look a portion of its impulse response for $M$ small; we can observe the periodic pattern of the reflections, together with a decaying magnitude:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(add_echo(1000, 100));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How does it sound? \n",
    "Let's load a brief speech sample that we will use in the rest of the notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fs, speech = wavfile.read('speech2.wav')\n",
    "speech = speech / 32767.0 # scale the signal to floats in [-1, 1]\n",
    "print('sampling rate:', Fs, 'Hz, data length:', len(speech), 'samples')\n",
    "IPython.display.Audio(speech, rate=Fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For audio signals, that's how the reverberation sounds for a delay to about 20ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_echo = add_echo(speech, int(0.020 * Fs))\n",
    "IPython.display.Audio(speech_echo, rate=Fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and we can easily convince ourselves that simple subtraction does not work; here we play the signal with echo first to compare volume levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Audio(np.r_[speech_echo, speech_echo - speech], rate=Fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. The LMS filter\n",
    "\n",
    "Let's now implement the standard LMS filter algorithm. Given the original signal $x[n]$ and its echo-corrupted version $d[n] = h[n] \\ast x[n]$, the LMS algorithm will estimate $h[n]$ iteratively as\n",
    "\n",
    "\\begin{align}\n",
    "  e[n] &= d[n] - \\mathbf{h}_{n}^{T} \\mathbf{x}_n \\\\\n",
    "  \\mathbf{h}_{n+1} &= \\mathbf{h}_n + \\alpha_n\\, e[n] \\, \\mathbf{x}_n\n",
    "\\end{align}\n",
    "\n",
    "where $\\mathbf{h}_n$ is the set of estimated filter coefficients at iteration $n$:\n",
    "$$\\mathbf{h}_n = \\begin{bmatrix} h_n[0] & h_n[1] & h_n[2] & \\ldots & h_n[N-1] \\end{bmatrix}$$\n",
    "and where\n",
    "$$\\mathbf{x}_n = \\begin{bmatrix} x[n] & x[n-1] & x[n-2] & \\ldots & x[n - N + 1] \\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lms(x, d, N, step_size=0.001):\n",
    "    # Run the LMS adaptation using x as the input signal, d as the desired output signal and a as the step size\n",
    "    # Will return an N-tap FIR filter\n",
    "    #\n",
    "    # initial guess for the filter is a delta\n",
    "    h = np.zeros(N)\n",
    "    h[0] = 1\n",
    "    # number of iterations\n",
    "    L = min(len(x), len(d))\n",
    "    # let's store the error at each iteration to plot the MSE\n",
    "    e = np.zeros(L)\n",
    "    # run the adaptation\n",
    "    for n in range(N, L):\n",
    "        e[n] = d[n] - np.dot(h, x[n:n-N:-1])\n",
    "        h = h + step_size * e[n] * x[n:n-N:-1]\n",
    "    return h, e[N:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convergence tests with WGN\n",
    "\n",
    "Let's now test the LMS filter using unit-variance white Gaussian noise as the input signal; with this maximally decorrelated input the convergence is faster. First, let's verify that the filter converges to a good approximation of the echo's impulse response:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the signals\n",
    "wgn = np.random.randn(10000)\n",
    "\n",
    "DELAY = 160\n",
    "wgn_echo = add_echo(wgn, DELAY)\n",
    "\n",
    "TAPS = 500\n",
    "h_orig = add_echo(TAPS, DELAY)\n",
    "\n",
    "def plot_lms_test(N, step_size=0.0008):\n",
    "    h_est, _ = lms(wgn[:N], wgn_echo[:N], TAPS, step_size)\n",
    "\n",
    "    plt.plot(h_orig, 'g', label='original impulse response'); \n",
    "    plt.plot(h_est, 'r', label=f'estimated impulse response ({N} iterations)');\n",
    "    plt.legend();\n",
    "    return h_est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lms_test(1000);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lms_test(2000);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_est = plot_lms_test(5000);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The approximation obtained with the highest number of iterations is actually quite good, as we can see by plotting the difference between the original and the estimated impulse response:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(h_orig - h_est);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly the precision depends on the number of steps in the adaptation. We can try and play with the value of the step size, for instance, and see how it affects the convergence. In the following example we see that increasing the learning factor actually decreases the precision of the estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_est = plot_lms_test(5000, step_size=0.002);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(h_orig - h_est);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increasing the learning factor even more prevents convergence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lms_test(5000, step_size=0.005);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eror decay\n",
    "\n",
    "To have a quantitative description of the convergence process we can average the value of the MSE at each instant over a set of independent experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wgn_mse(L, step_size=0.0008):\n",
    "    wgn = np.random.randn(L)\n",
    "    wgn_echo = add_echo(wgn, DELAY)\n",
    "    _, err = lms(wgn, wgn_echo, TAPS, step_size)\n",
    "    return np.square(err)\n",
    "    \n",
    "    \n",
    "TRIALS = 200 # number of independent experiments\n",
    "L = 6000\n",
    "\n",
    "mse = wgn_mse(L)\n",
    "for n in range(1, TRIALS):\n",
    "    mse = mse + wgn_mse(L)\n",
    "mse = mse / TRIALS   \n",
    "plt.plot(mse);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, with these parameters the error stops decreasing after about 3000 iterations. Here too you can play with the step size and see how it affects the convergence rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. The LMS echo canceler\n",
    "\n",
    "Let's now run the LMS adaptation using a voice signal as the input. Since the voice signal is very correlated, the convergenge will be slower, but we can use a much larger step size. Since our sound snippet is short, we will use it multiple times in the adaptation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's build the echo signal with a 20ms delay\n",
    "speech_echo_delay = int(0.020 * Fs)\n",
    "audio = np.tile(speech, 5) \n",
    "\n",
    "# now let's estimate the first 1000 taps of the echo impulse response using the speech signal\n",
    "speech_echo_taps = 1500\n",
    "h_est, err = lms(audio, add_echo(audio, speech_echo_delay), speech_echo_taps, step_size=0.021)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we plot the difference between the ideal and estimated impulse response we can see that the match is not perfect. This is because the speech signal, as opposed to white noise, does not drive the adaptation as effectively since it doesn't \"hit\" all of the frequencies. You can try and use more copies of the audio in sequence to improve the adaptation; in a normal use case the LMS filter would be running all the time, using much more data to converge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_orig = add_echo(len(h_est), speech_echo_delay)\n",
    "\n",
    "plt.plot(h_orig, 'g', label='original impulse response'); \n",
    "plt.plot(h_est, 'r', label=f'estimated impulse response ({len(audio)} iterations)');\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(h_orig - h_est);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now listen to the effectiveness of the echo canceler; listen in sequence to the reverberated sound, the cancellation performed by simple subtraction and the cancellation after filtering with the coefficients produced by the LMS adaptation. The results should speak for themselves!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_echo = add_echo(speech, speech_echo_delay)\n",
    "speech_echo_estimated = sp.lfilter(h_est, 1, speech)\n",
    "\n",
    "audio_sequence = np.r_[speech_echo, speech_echo - speech, speech_echo - speech_echo_estimated]\n",
    "\n",
    "IPython.display.Audio(audio_sequence, rate=Fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(audio_sequence);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
